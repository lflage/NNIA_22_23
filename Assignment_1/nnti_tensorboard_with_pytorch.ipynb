{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7qm6bwNRFPyH"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQfocQODFPyL"
   },
   "source": [
    "\n",
    "How to use TensorBoard with PyTorch\n",
    "===================================\n",
    "TensorBoard is a visualization toolkit for machine learning experiments. \n",
    "TensorBoard allows tracking and visualizing metrics such as *loss* and *accuracy*, \n",
    "visualizing the model graph, viewing histograms, displaying images and much more. \n",
    "In this tutorial we are going to cover basic usage of TensorBoard with PyTorch, and how to visualize the data you logged in TensorBoard UI.\n",
    "\n",
    "It's OK if you don't understand everything in this notebook right now, but it will help you in the future (especially with the project).\n",
    "\n",
    "Installation\n",
    "----------------------\n",
    "PyTorch should be installed to log models and metrics into TensorBoard log \n",
    "directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpG9oq5MFPyM"
   },
   "source": [
    "Using TensorBoard in PyTorch\n",
    "-----\n",
    "\n",
    "Let’s now try using TensorBoard with PyTorch! Before logging anything, \n",
    "we need to create a ``SummaryWriter`` instance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "73HCdIXfFPyM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sx1zl-ETFPyP"
   },
   "source": [
    "Writer will output to ``./runs/`` directory by default.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxHcAknfFPyP"
   },
   "source": [
    "Log scalars\n",
    "-----\n",
    "\n",
    "In machine learning, it’s important to understand key metrics such as \n",
    "*loss* and how they change during model training. Scalar helps to save \n",
    "the *loss* value of each training step (e.g., one minibatch), or the *accuracy* after each epoch. \n",
    "\n",
    "To log a scalar value, use \n",
    "``add_scalar(tag, scalar_value, global_step=None, walltime=None)``. \n",
    "For instance, let's perform a simple linear regression training, and \n",
    "log the loss value using ``add_scalar``\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cBCs6Q2aFPyQ"
   },
   "outputs": [],
   "source": [
    "# input tensors\n",
    "x = torch.arange(-5, 5, 0.1).view(-1, 1)\n",
    "y = -5 * x + 0.1 * torch.randn(x.size())\n",
    "\n",
    "# a simple linear model\n",
    "model = torch.nn.Linear(1, 1)\n",
    "\n",
    "# mean squared error objective\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# plain Stochastic Gradient Descent optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "\n",
    "def train_model(iterations):\n",
    "    for epoch in range(iterations):\n",
    "        # forward pass\n",
    "        y1 = model(x)\n",
    "        \n",
    "        # compute loss\n",
    "        loss = criterion(y1, y)\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)   # log the loss values\n",
    "        \n",
    "        # stop gradient accumulation\n",
    "        # read more here: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch/\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # update parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "iterations = 10\n",
    "train_model(iterations)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rp9K2GqxFPyS"
   },
   "source": [
    "Call ``flush()`` method to make sure that all pending events \n",
    "have been written to the disk.\n",
    "\n",
    "See [torch.utils.tensorboard tutorials](https://pytorch.org/docs/stable/tensorboard.html) to find more TensorBoard visualization types you can log.\n",
    "\n",
    "If you do not need the summary writer anymore, call the ``close()`` method.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IRSe6eHcFPyT"
   },
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFKETpE2F2oE",
    "tags": []
   },
   "source": [
    "Visualize in TensorBoard\n",
    "-----\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUoj8fC4FPyV"
   },
   "source": [
    "Simply visit the URL: [http://localhost:6006](http://localhost:6006/). By default, `./runs` directory will be used by PyTorch's built-in tensorboard.\n",
    "\n",
    "----\n",
    "\n",
    "It is also possible to write the event files to a different location and then explicitly launch TensorBoard from the command line by specifying the root log directory you used above while writing the event files. Command line argument ``logdir`` points to the directory where TensorBoard will look to find \n",
    "event files that it can display. TensorBoard will recursively walk the directory structure rooted at logdir, looking for \\*.tfevents.\\* files.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-qupXpbGH8k"
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDH-98FkGIvs"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pytorch/tutorials/master/_static/img/thumbnails/tensorboard_scalars.png\" width=\"700\"/>\n",
    "\n",
    "\n",
    "This dashboard shows how the *loss* and *accuracy* change with every epoch. \n",
    "You can use it to also track training speed, learning rate, and other \n",
    "scalar values. It’s helpful to compare these metrics across different \n",
    "training runs to improve your model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_k2RbNizFPyW"
   },
   "source": [
    "Learn More\n",
    "----------------------------\n",
    "\n",
    "-  [torch.utils.tensorboard](https://pytorch.org/docs/stable/tensorboard.html) Documentation\n",
    "-  [Visualizing models, data, and training with TensorBoar](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html) Tutorial\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "tensorboard_with_pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
